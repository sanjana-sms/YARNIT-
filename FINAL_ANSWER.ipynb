{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zuB7c7dSc5n",
        "outputId": "e1a5f078-e366-4207-d04d-2b476eb7083d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai #OpenAI python library\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "eUqwSzjhTMHl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mzNriemTQJ8",
        "outputId": "18c81be8-3e64-4552-e0c9-005000b7e059"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "openai_api_key=os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "soBd36AsTXgw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key=\"sk-proj-raiyBZVF0OADZ6nL5GSfT3BlbkFJ47z7YR1AeGh64H0w0O9B\""
      ],
      "metadata": {
        "id": "fcI2EhfATcsU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "BhP_bpRnT0ek"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "    ],\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1CMT9xiT7RV",
        "outputId": "9f471c02-b321-461a-9d16-1eb7ed77ee94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "    ]"
      ],
      "metadata": {
        "id": "MOMhoC7LUC3B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"text\\\": \\\"to request the API to generate marketing content on Generative AI. The question to call the API function could be anything you want\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you generate marketing content on Generative AI using the provided text?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "BTorPjWjUHue"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the API key\n",
        "!pip install openai\n",
        "import openai\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Call the API and capture the response\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"text\\\": \\\"to request the API to generate marketing content on Generative AI. The question to call the API function could be anything you want\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you generate marketing content on Generative AI using the provided text?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Check the response type\n",
        "print(type(response))\n",
        "\n",
        "# Print the response content\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meRZl77XXxj7",
        "outputId": "3a4a94d2-4bb1-4278-ca5a-1bf0f91a5bbc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "<class 'openai.types.chat.chat_completion.ChatCompletion'>\n",
            "Yes, of course! Here is an example of marketing content generated by a Generative AI for Generative AI technology:\n",
            "\n",
            "\"Revolutionize your marketing strategy with the power of Generative AI. Unlock the potential to create personalized, engaging content at scale, driving customer engagement and boosting conversions. Stay ahead of the competition and unleash endless creativity with Generative AI. Elevate your brand and connect with your audience on a whole new level. Discover the future of marketing with Generative AI today!\"\n",
            "\n",
            "Feel free to let me know if you would like any additional information or more content on this topic!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c59pVTNKYCGU",
        "outputId": "d8debaba-a04e-457d-96c9-138cb70d1176"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, of course! Here is an example of marketing content generated by a Generative AI for Generative AI technology:\n",
            "\n",
            "\"Revolutionize your marketing strategy with the power of Generative AI. Unlock the potential to create personalized, engaging content at scale, driving customer engagement and boosting conversions. Stay ahead of the competition and unleash endless creativity with Generative AI. Elevate your brand and connect with your audience on a whole new level. Discover the future of marketing with Generative AI today!\"\n",
            "\n",
            "Feel free to let me know if you would like any additional information or more content on this topic!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the API and capture the response\n",
        "response = client.chat.completions.create\n",
        "model=\"gpt-3.5-turbo\",\n",
        "messages=[\n",
        "        {\"role\": \"system\", \"content\": \"to request the API to generate marketing content on Generative AI. The question to call the API function could be\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you generate marketing content on Generative AI using the provided text?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \" example of marketing content generated by a Generative AI for Generative AI technology:\"}\n",
        "    ]\n",
        "\n",
        "\"Revolutionize your marketing strategy with the power of Generative AI. Unlock the potential to create personalized, engaging content at scale, driving customer engagement and boosting conversions. Stay ahead of the competition and unleash endless creativity with Generative AI. Elevate your brand and connect with your audience on a whole new level. Discover the future of marketing with Generative AI today!\"\n",
        "\n",
        "{\"Feel free to let me know if you would like any additional information or more content on this topic!\"},\n",
        "{\"role\": \"user\", \"content\": \"can you generate marketing content on generative AI?\"},\n",
        "{\"role\":\"assistant\",\"content\":\"example of marketing content generated by a generative AI for generative AI technology:\"}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvJmE0CbaQPs",
        "outputId": "13ad0469-0167-4fea-f3ba-972796fb92bd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': 'example of marketing content generated by a generative AI for generative AI technology:'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt_call(model:str=\"gpt-3.5-turbo\",prompt:str=\"Have \\\n",
        "    I provided any input\",n:int=1,max_tokens:int=100,\n",
        "    temperature:float=0.5,presence_penalty:float=0):\n",
        "\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "       {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens=max_tokens,\n",
        "    temperature=temperature,\n",
        "    presence_penalty=presence_penalty,\n",
        "    n=n\n",
        "    )\n",
        "\n",
        "\n",
        "    if len(response.choices)>1:\n",
        "        output = ''\n",
        "        for i in range(0, len(response.choices)):\n",
        "            output += '\\n\\n-- n = ' + str(i + 1) + ' ------\\n\\n' + \\\n",
        "                     str(response.choices[i].message.content)\n",
        "    else:\n",
        "         output=response.choices[0].message.content\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "WcnQ0TaXc6Uc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_call(prompt=\"Write a title for a workshop on openai API\",n=2,temperature=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0WM7jZ3dXg_",
        "outputId": "847c42b2-d6bf-42af-e6f7-b9d9bb78f41c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "-- n = 1 ------\n",
            "\n",
            "\"Unlocking the Potential of OpenAI: A Hands-On Workshop on API Integration\"\n",
            "\n",
            "-- n = 2 ------\n",
            "\n",
            "\"Diving into the World of AI with OpenAI API: A Hands-On Workshop\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n = 1 ------\n",
        "\n",
        "\"Unlocking the Power of AI: A Deep Dive into OpenAI's API\"\n",
        "\n",
        "# n = 2 ------\n",
        "\n",
        "print(\"Unlocking the Power of OpenAI: A Workshop on Leveraging the OpenAI\\nAPI for Innovation and Insight\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfIjsCj-diWO",
        "outputId": "4a802ac4-0aab-4f6d-d1bc-c9e13503b9cf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unlocking the Power of OpenAI: A Workshop on Leveraging the OpenAI\n",
            "API for Innovation and Insight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_call(prompt=\"Write a title for a workshop on openai API\",n=3,temperature=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbmQbJNsduDk",
        "outputId": "9cc95f25-38f1-4a57-e533-8e9dfe465322"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "-- n = 1 ------\n",
            "\n",
            "\"Unlocking the Power of OpenAI: A Hands-On Workshop on Harnessing the OpenAI API\"\n",
            "\n",
            "-- n = 2 ------\n",
            "\n",
            "\"Unlocking the Power of OpenAI: A Hands-On Workshop on Harnessing the OpenAI API\"\n",
            "\n",
            "-- n = 3 ------\n",
            "\n",
            "\"Unlocking the Power of OpenAI: A Hands-On Workshop on Harnessing the OpenAI API\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null= None\n",
        "\n",
        "model ={\n",
        "     \"id\": \"chatcmpl-99vyDS2agqm7zz8ZB3WJ960QWPp9B\",\n",
        "     \"choices\": [\n",
        "          {\n",
        "               \"finish_reason\": \"stop\",\n",
        "               \"index\": 0,\n",
        "               \"logprobs\": null,\n",
        "               \"message\": {\n",
        "                    \"content\": \"unlocking the power of AI : a deep dive into openai's API\",\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"function_call\": null,\n",
        "                    \"tool_calls\": null\n",
        "               }\n",
        "          }\n",
        "     ],\n",
        "     \"created\": 1712154817,\n",
        "     \"model\": \"gpt-3.5-turbo-0125\",\n",
        "     \"object\": \"chat.completion\",\n",
        "     \"system_fingerprint\": \"fp_b28b39ffa8\",\n",
        "     \"usage\": {\n",
        "          \"completion_tokens\": 59,\n",
        "          \"prompt_tokens\": 77,\n",
        "          \"total_tokens\": 136\n",
        "     }\n",
        "}"
      ],
      "metadata": {
        "id": "u_xA54NblXKX"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in the field of AI.\"},\n",
        "    {\"role\": \"user\", \"content\": \"can you generate marketing content on generative AI\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Unlocking the Power of AI: A Deep Dive into OpenAI's API\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you generate marketing content on Generative AI using the provided text?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"example of marketing content generated by a Generative AI for Generative AI technology\"},\n",
        "  ],\n",
        "  stream=True ###Streaming is set to true here.\n",
        ")"
      ],
      "metadata": {
        "id": "4648jMiRmY8C"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in response.choices:\n",
        "  if chunk.message.content is not None:\n",
        "    print(chunk.message.content, end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "kEhGwxi2nk-i",
        "outputId": "8115df36-c762-44d4-bac6-aa7f51015f75"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Stream' object has no attribute 'choices'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-2b87dc892e11>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Stream' object has no attribute 'choices'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in response.iter_lines():\n",
        "    if chunk.strip():\n",
        "        print(chunk.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "DGbikBEun-Wd",
        "outputId": "7f3aa2df-cd11-46ba-858f-3fa4427af7f5"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Stream' object has no attribute 'iter_lines'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-0be4666df86e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Stream' object has no attribute 'iter_lines'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"Title\": \"Unlocking the Power of AI: A Deep Dive into OpenAI's API.\",\n",
        "    \"Body\": \"You are a helpful assistant knowledgeable in the field of AI.\"\n",
        "}\n",
        "    \"Heading\": [],\n",
        "    \"body\": [\n",
        "            \"\"\"\n",
        "        \"You are a helpful assistant knowledgeable in the field of AI..\"\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        \"Unlocking the Power of AI: A Deep Dive into OpenAI's API.\",\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        \"Example of marketing content generated by a Generative AI for Generative AI technology.\"\n",
        "        \"\"\"\n",
        "    ]\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IGUsEIk3oN1z",
        "outputId": "79593b69-5ffd-4c6a-cefd-2b3d8e312d76"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-183-a7492d5dfe21>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-183-a7492d5dfe21>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \"Heading\": [],\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}