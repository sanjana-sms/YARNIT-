{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF3efPBTYITf",
        "outputId": "c196b95d-5ea0-4745-cab9-d99f62678ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.2-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai #OpenAI python library\n",
        "from openai import OpenAI #OpenAI Client"
      ],
      "metadata": {
        "id": "dnFnrUSPbhCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVR711XbpxO",
        "outputId": "6ab4896a-77cb-4315-f6e7-4548f883d893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "openai_api_key=os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "ID1snBJwb2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key=\"sk-proj-raiyBZVF0OADZ6nL5GSfT3BlbkFJ47z7YR1AeGh64H0w0O9B\""
      ],
      "metadata": {
        "id": "u4U340r2b6Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9lFyEcwIIZc",
        "outputId": "d994e2e9-d9f4-4fea-8540-14621e868681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\n",
        "linkedin_profile_url = 'https://www.linkedin.com/in/pradipnichite/'\n",
        "api_key = 'sk-proj-raiyBZVF0OADZ6nL5GSfT3BlbkFJ47z7YR1AeGh64H0w0O9B'\n",
        "headers = {'Authorization': 'Bearer ' + 'sk-proj-raiyBZVF0OADZ6nL5GSfT3BlbkFJ47z7YR1AeGh64H0w0O9B'}\n",
        "\n",
        "response = requests.get(api_endpoint,\n",
        "                        params={'url': linkedin_profile_url,'skills': 'include'},\n",
        "                        headers=headers)\n"
      ],
      "metadata": {
        "id": "Q1BI4m5Y3Oe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile_data = response.json()\n",
        "profile_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaw3ZQbZ9JlX",
        "outputId": "6281c441-dccc-4fb1-ad58-76bf3b858079"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': 401, 'description': 'Invalid API key', 'name': 'Unauthorized'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Documentation : https://nubela.co/proxycurl/docs#people-api-person-profile-endpoint"
      ],
      "metadata": {
        "id": "OoIJcDy_9nze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS THE API KEY IS NOT WORKING I'll JUST GONNA SHOW THE ROUGH WORKING OF WHAT I THOUGHT !!"
      ],
      "metadata": {
        "id": "iL0KTN1R-Gaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profile_data.keys()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rv1ixtI-zYM",
        "outputId": "cfae980f-38fb-4d7c-8080-f764d494d483"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['code', 'description', 'name'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\":\n",
        "      \"authorship_tag\": \"ABX9TyNIdmBXKjD/ozhgBXbxu0LA\",\n",
        "      \"include_colab_link\": True\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/PradipNichite/Youtube-Tutorials/blob/main/Proxycurl_API.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"###Proxycurl API is a LinkedIn Profile Scraping API\\n\",\n",
        "        \"\\n\",\n",
        "        \"**Use Cases:**\\n\",\n",
        "        \"\\n\",\n",
        "        \"Building Data Driven Applications. (Lead Generation, Prospecting etc)\\n\",\n",
        "        \"\\n\",\n",
        "        \"Eg. Leveraging NLP like GPT-3 to Write Personalize Email , Message, LinkedIn Invitation based on their profile info like Occuption, Experince, Summary etc\\n\",\n",
        "        \"\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"1Y4A8_YBRPUT\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"https://nubela.co/proxycurl/linkedin\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"yVE-f8jaMhM0\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"6oB6xcAYRVnl\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 1,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"YDuNussNMRz4\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import requests\\n\",\n",
        "        \"api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\\n\",\n",
        "        \"linkedin_profile_url = 'https://www.linkedin.com/in/pradipnichite/'\\n\",\n",
        "        \"api_key = 'sk-proj-raiyBZVF0OADZ6nL5GSfT3BlbkFJ47z7YR1AeGh64H0w0O9B'\\n\",\n",
        "        \"headers = {'Authorization': 'Bearer ' + api_key}\\n\",\n",
        "        \"\\n\",\n",
        "        \"response = requests.get(api_endpoint,\\n\",\n",
        "        \"                        params={'url': linkedin_profile_url,'skills': 'include'},\\n\",\n",
        "        \"                        headers=headers)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data = response.json()\\n\",\n",
        "        \"profile_data\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"uzC4ZKBTOINR\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"API Documentation : https://nubela.co/proxycurl/docs#people-api-person-profile-endpoint\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"pL7dSyRrQ92R\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data.keys()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"IkJz8IfzOYUz\",\n",
        "        \"outputId\": \"928c9b21-29ee-4491-d4d7-71a5df53884a\"\n",
        "      },\n",
        "      \"execution_count\": 3,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"dict_keys(['public_identifier', 'profile_pic_url', 'background_cover_image_url', 'first_name', 'last_name', 'full_name', 'occupation', 'headline', 'summary', 'country', 'country_full_name', 'city', 'state', 'experiences', 'education', 'languages', 'accomplishment_organisations', 'accomplishment_publications', 'accomplishment_honors_awards', 'accomplishment_patents', 'accomplishment_courses', 'accomplishment_projects', 'accomplishment_test_scores', 'volunteer_work', 'certifications', 'connections', 'people_also_viewed', 'recommendations', 'activities', 'similarly_named_profiles', 'articles', 'groups', 'skills'])\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 3\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['full_name']\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 35\n",
        "        },\n",
        "        \"id\": \"gFy1plfyOhvU\",\n",
        "        \"outputId\": \"029ce97b-3a69-41f1-9059-8a40d5f9e789\"\n",
        "      },\n",
        "      \"execution_count\": 4,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"'Pradip Nichite'\"\n",
        "            ],\n",
        "            \"application/vnd.google.colaboratory.intrinsic+json\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 4\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['occupation']\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 35\n",
        "        },\n",
        "        \"id\": \"G8OLSSvRO8ED\",\n",
        "        \"outputId\": \"86986785-7f2d-46cb-86bd-cce97ffb9d4c\"\n",
        "      },\n",
        "      \"execution_count\": 5,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"'Freelance Data Scientist at Upwork'\"\n",
        "            ],\n",
        "            \"application/vnd.google.colaboratory.intrinsic+json\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 5\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['headline']\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 35\n",
        "        },\n",
        "        \"id\": \"OXW9VVTePDiL\",\n",
        "        \"outputId\": \"18f0f458-020a-44d1-c352-67c29c64dcea\"\n",
        "      },\n",
        "      \"execution_count\": 6,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"'Freelance Data Scientist | Custom NLP Solutions | Consultant | GPT-3 | Amazon Lex Chatbot'\"\n",
        "            ],\n",
        "            \"application/vnd.google.colaboratory.intrinsic+json\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 6\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"print(profile_data['summary'])\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"D8Dt0L3XPFOb\",\n",
        "        \"outputId\": \"99043e97-94a9-46f8-b5ef-669394350b2c\"\n",
        "      },\n",
        "      \"execution_count\": 7,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Top Rated Freelancer on Upwork, delivered multiple end-to-end NLP projects, leveraging Transformers, GPT-3, Spacy, Amazon Lex chatbots, AWS, etc.\\n\",\n",
        "            \"\\n\",\n",
        "            \"✅ Machine Learning Engineer with 7+ years of experience in (Machine Learning, NLP, Big Data, and Back-End Development). M.Tech I.T. with specialization in Data Science with 9.2/10 CGPA.\\n\",\n",
        "            \"\\n\",\n",
        "            \"✅ Experience building end-to-end machine learning systems using Natural Language Processing and MLOps.\\n\",\n",
        "            \"\\n\",\n",
        "            \"✅ During my M. Tech, I Studied Machine Learning, Deep Learning, and its applications to NLP and Computer vision.\\n\",\n",
        "            \"\\n\",\n",
        "            \"✅ In the Past, I have worked as a Software Developer and developed back-end and ReST API for web applications.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Skills:\\n\",\n",
        "            \"\\n\",\n",
        "            \"Languages: Python, JavaScript, SQL.\\n\",\n",
        "            \"\\n\",\n",
        "            \"ML Libraries: Pandas, Scikit learn, Spacy, Gensim, Pytorch, Transformers, Rasa, Haystack.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Other: AWS, Flask,  FastAPI, GPT-3\\n\",\n",
        "            \"\\n\",\n",
        "            \"Book a time with Pradip at https://topmate.io/ML \\n\",\n",
        "            \"1:1 Mentorship | Mock Interview For Data Scientist and ML Engineer\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['experiences']\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"0DOUACD_QEhg\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['experiences'][2]\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"7eOAQf0XPJrq\",\n",
        "        \"outputId\": \"224ce9cb-cd2a-47ef-f76c-76e79cd854f5\"\n",
        "      },\n",
        "      \"execution_count\": 9,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"{'starts_at': {'day': 1, 'month': 9, 'year': 2021},\\n\",\n",
        "              \" 'ends_at': {'day': 28, 'month': 2, 'year': 2022},\\n\",\n",
        "              \" 'company': 'Oracle',\\n\",\n",
        "              \" 'company_linkedin_profile_url': 'https://in.linkedin.com/company/oracle',\\n\",\n",
        "              \" 'title': 'Tech Lead - Data Science',\\n\",\n",
        "              \" 'description': 'Machine Learning Solutions for Oracle Cloud Products.',\\n\",\n",
        "              \" 'location': None,\\n\",\n",
        "              \" 'logo_url': 'https://media-exp1.licdn.com/dms/image/D4E0BAQHYCgYovUuPtQ/company-logo_100_100/0/1665755678671?e=2147483647&v=beta&t=BBjGBVZ-kcxvjwTFPVNymoU4ilfvgMSDDovXm5R2lS4'}\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 9\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['education']\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"W4NUiPh1PPqT\",\n",
        "        \"outputId\": \"c4ddf152-1b9a-4643-e78b-f219a31a74d2\"\n",
        "      },\n",
        "      \"execution_count\": 10,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"[{'starts_at': {'day': 1, 'month': 1, 'year': 2016},\\n\",\n",
        "              \"  'ends_at': {'day': 31, 'month': 12, 'year': 2018},\\n\",\n",
        "              \"  'field_of_study': 'Data Science',\\n\",\n",
        "              \"  'degree_name': 'Master of Technology - MTech',\\n\",\n",
        "              \"  'school': 'International Institute of Information Technology – Bangalore',\\n\",\n",
        "              \"  'school_linkedin_profile_url': 'https://in.linkedin.com/school/iiit-bangalore/',\\n\",\n",
        "              \"  'description': 'M.Tech I.T. with specialization in Data Science with 9.2/10 CGPA. Studied Machine Learning, Deep Learning, and its applications to NLP and Computer vision.',\\n\",\n",
        "              \"  'logo_url': 'https://media-exp1.licdn.com/dms/image/D560BAQFEoOigRO63qg/company-logo_100_100/0/1664105399908?e=2147483647&v=beta&t=03DZ93PTiwSrLhIQxVBzn-jrxo_Vo6tk1QCR4FayWkQ',\\n\",\n",
        "              \"  'grade': None,\\n\",\n",
        "              \"  'activities_and_societies': None},\\n\",\n",
        "              \" {'starts_at': {'day': 1, 'month': 1, 'year': 2009},\\n\",\n",
        "              \"  'ends_at': {'day': 31, 'month': 12, 'year': 2013},\\n\",\n",
        "              \"  'field_of_study': 'Information Technology',\\n\",\n",
        "              \"  'degree_name': 'Bachelor of Technology (B.Tech.)',\\n\",\n",
        "              \"  'school': 'Dr.Babasaheb Ambedkar Technological University, Lonere - Raigad',\\n\",\n",
        "              \"  'school_linkedin_profile_url': 'https://in.linkedin.com/school/dr.babasaheb-ambedkar-technological-university-lonere---raigad/',\\n\",\n",
        "              \"  'description': 'B.Tech In Information Technology',\\n\",\n",
        "              \"  'logo_url': None,\\n\",\n",
        "              \"  'grade': None,\\n\",\n",
        "              \"  'activities_and_societies': None},\\n\",\n",
        "              \" {'starts_at': {'day': 1, 'month': 1, 'year': 2004},\\n\",\n",
        "              \"  'ends_at': {'day': 31, 'month': 12, 'year': 2009},\\n\",\n",
        "              \"  'field_of_study': None,\\n\",\n",
        "              \"  'degree_name': 'Science',\\n\",\n",
        "              \"  'school': 'G.V.Khade Vidyalaya Shahapur,Thane,Maharashtra',\\n\",\n",
        "              \"  'school_linkedin_profile_url': None,\\n\",\n",
        "              \"  'description': None,\\n\",\n",
        "              \"  'logo_url': None,\\n\",\n",
        "              \"  'grade': None,\\n\",\n",
        "              \"  'activities_and_societies': None}]\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 10\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['education'][0]\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"FlLpCfcTQH1S\",\n",
        "        \"outputId\": \"e2d8062c-fcf7-4a56-94cc-c59df0362f42\"\n",
        "      },\n",
        "      \"execution_count\": 11,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"{'starts_at': {'day': 1, 'month': 1, 'year': 2016},\\n\",\n",
        "              \" 'ends_at': {'day': 31, 'month': 12, 'year': 2018},\\n\",\n",
        "              \" 'field_of_study': 'Data Science',\\n\",\n",
        "              \" 'degree_name': 'Master of Technology - MTech',\\n\",\n",
        "              \" 'school': 'International Institute of Information Technology – Bangalore',\\n\",\n",
        "              \" 'school_linkedin_profile_url': 'https://in.linkedin.com/school/iiit-bangalore/',\\n\",\n",
        "              \" 'description': 'M.Tech I.T. with specialization in Data Science with 9.2/10 CGPA. Studied Machine Learning, Deep Learning, and its applications to NLP and Computer vision.',\\n\",\n",
        "              \" 'logo_url': 'https://media-exp1.licdn.com/dms/image/D560BAQFEoOigRO63qg/company-logo_100_100/0/1664105399908?e=2147483647&v=beta&t=03DZ93PTiwSrLhIQxVBzn-jrxo_Vo6tk1QCR4FayWkQ',\\n\",\n",
        "              \" 'grade': None,\\n\",\n",
        "              \" 'activities_and_societies': None}\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 11\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"profile_data['skills']\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"1a34za_4QLHy\",\n",
        "        \"outputId\": \"43b0224a-7f36-4bc5-9e1c-24585b2fcf5f\"\n",
        "      },\n",
        "      \"execution_count\": 12,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"['ad targeting',\\n\",\n",
        "              \" 'adtech',\\n\",\n",
        "              \" 'algorithms',\\n\",\n",
        "              \" 'amazon web services',\\n\",\n",
        "              \" 'analytics',\\n\",\n",
        "              \" 'apache spark',\\n\",\n",
        "              \" 'artificial intelligence',\\n\",\n",
        "              \" 'automl',\\n\",\n",
        "              \" 'aws elastic beanstalk',\\n\",\n",
        "              \" 'big data analytics',\\n\",\n",
        "              \" 'computer vision',\\n\",\n",
        "              \" 'continuous integration and continuous delivery',\\n\",\n",
        "              \" 'data analysis',\\n\",\n",
        "              \" 'data cleaning',\\n\",\n",
        "              \" 'data modeling',\\n\",\n",
        "              \" 'data preparation',\\n\",\n",
        "              \" 'data processing',\\n\",\n",
        "              \" 'data products',\\n\",\n",
        "              \" 'data science',\\n\",\n",
        "              \" 'databricks',\\n\",\n",
        "              \" 'flask',\\n\",\n",
        "              \" 'hadoop',\\n\",\n",
        "              \" 'hive',\\n\",\n",
        "              \" 'html',\\n\",\n",
        "              \" 'java',\\n\",\n",
        "              \" 'javascript',\\n\",\n",
        "              \" 'jenkins',\\n\",\n",
        "              \" 'jquery',\\n\",\n",
        "              \" 'keras',\\n\",\n",
        "              \" 'linux',\\n\",\n",
        "              \" 'machine learning',\\n\",\n",
        "              \" 'martech',\\n\",\n",
        "              \" 'mathematics',\\n\",\n",
        "              \" 'mysql',\\n\",\n",
        "              \" 'natural language processing',\\n\",\n",
        "              \" 'numpy',\\n\",\n",
        "              \" 'pandas',\\n\",\n",
        "              \" 'php',\\n\",\n",
        "              \" 'predictive modeling',\\n\",\n",
        "              \" 'product analysis',\\n\",\n",
        "              \" 'python',\\n\",\n",
        "              \" 'representational state transfer',\\n\",\n",
        "              \" 'scala',\\n\",\n",
        "              \" 'scalable machine learning',\\n\",\n",
        "              \" 'scikit learn',\\n\",\n",
        "              \" 'software development',\\n\",\n",
        "              \" 'spark',\\n\",\n",
        "              \" 'sql',\\n\",\n",
        "              \" 'tensorflow',\\n\",\n",
        "              \" 'web scraping']\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {},\n",
        "          \"execution_count\": 12\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"tIyJWjXuWLcT\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "rgGFDCU_JyLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE TO GENERATE NESCESSARY INFORMATION ABOUT A LINKEDIN PROFILE"
      ],
      "metadata": {
        "id": "YL4rRPIxKUOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profile_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ivZmnp_KjK9",
        "outputId": "f7c22ad5-c765-4326-a478-be42e6376aa2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['code', 'description', 'name'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(profile_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O9RS8-jK96i",
        "outputId": "4ad556e2-01b4-4f16-af37-200b6d334d0a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'code': 401, 'description': 'Invalid API key', 'name': 'Unauthorized'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "occupation = profile_data['occupation']"
      ],
      "metadata": {
        "id": "OuUw9eOONFBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(profile_data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhdRGTNTM1sX",
        "outputId": "5cfba2ac-95e0-4fa8-da31-775b46d041c3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['code', 'description', 'name'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(profile_data.get('summary', \"The 'summary' key does not exist in the profile_data dictionary.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPsN74hZNYjP",
        "outputId": "ad8d0387-5eba-41de-87a8-f652a1f1ce46"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'summary' key does not exist in the profile_data dictionary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BY GIVING ALL THE DATA TO THE CODE AND THEN USING IT AS A PREVIEW"
      ],
      "metadata": {
        "id": "FoYk8c8vNvll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "API ENDPOINT THAT IS PROXY CURLY WHICH FETCHES ITS URL ,API KEY AND A LINKEDIN PROFILE URL AND IMPOERTANT DATA WHILE FETCHING THE DATA."
      ],
      "metadata": {
        "id": "48X0uvBwOIPo"
      }
    }
  ]
}